---
title: "Lab02: Data Manipulation and Visualization with R"
author: "Pineapple Seahawks"
output:
  html_document:
    toc: true
    toc_depth: 2
    number_sections: true
    theme: cosmo
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE
)
```

# Overview

In this lab, your team will explore the online advertising auctions data.
Your goals are to:

-   Practice **data manipulation** in R (using tidyverse).
-   Practice **data visualization** using concepts from the Data Visualization session.
-   Identify **3–4 data quality issues** that would matter in a real analysis workflow.
-   Communicate results clearly and professionally as a team.

This lab is designed to take **2–3 hours** of focused collaborative work.

> Today, you are only exploring, visualizing, interpreting, and identifying suspicious looking issues.

------------------------------------------------------------------------

# Git Workflow, Collab, and Use of Generative AI

This is a **team-based exploratory analysis**.

## Git Workflow

-   **One team member** should fork the course lab repository.
-   In the team’s cloned fork, create the `data/` folder:
-   That person should **add the rest of the team as collaborators**.
-   All team members should clone the **same shared fork** (creating an RStudio project).

To keep collaboration smooth:

-   Pull before you start working.
-   Commit frequently, with clear messages (e.g., "added price histogram", "investigated region codes").
-   Remember to pull before pushing.
-   Push your work regularly.

I will review the **Git commit history** to understand who contributed what.
Individual grades depend on **meaningful contribution** from each student.

## Team Planning (Required)

Before you begin, read the entire lab together (5–10 minutes).

-   Make sure everyone understands the goals, deliverables, and sections.

Decide how to divide the work (3–4 members).

-   As a team, choose a coordinator for each major section, and within sections split the work

    * Section 1: Initial Orientation
    * Section 2: Data Exploration (dplyr)
    * Section 3: Visualizations
    * Section 4: Synthesis & Reflection
    
-   Section coordinators will ensure their sections are completed throughout the lab's development

Create a Jira Kanban Board (team facilitator).

-   Go to Jira → Create Project → Kanban template

-   Create a board titled: “Ad Bids Lab – Team <YourTeamName>”

-   Add cards for each task/subtask, including:

    * Task name
    * Description
    * Assigned team member
    * Due date (based on team timeline)
    
Upload a screenshot (I'll check the time and date of the file) of the Kanban board.

-   A screenshot showing all initial cards in the To Do column and assignments.

-   Save it in your repository under: `planning/kanban_screenshot.png`

-   Add it **here**.

Make use of the team charter that you designed in Lab01, using the Kanban board throughout the project to keep you on task, correcting issues that arise and readjusting as needed.


## Use of Generative AI

You **may** use Gen.AI tools **as support**, not as a replacement.

Appropriate AI uses:

-   Understanding R errors
-   Asking for explanations of functions & syntax
-   Debugging when stuck
-   Checking whether your code is reasonable

Inappropriate uses:

-   Asking AI to complete most or all of the lab
-   Copying AI-generated code you don’t understand
-   Using AI to write your interpretations or summaries

Your code and reasoning must reflect **your own team’s understanding**.

------------------------------------------------------------------------


# Data and Setup

1.  Each team member should download from Canvas two files in `Modules → ProjectInformation`:

-   `bids_data_vDTR.parquet`

-   A **data dictionary** describing each variable

3.  In your local repo add the data and data dictionary to the `data` folder

4.  Add the data and dictionary file to your .gitignore

5.  Verify that Git is ignoring the files (in the RStudio terminal write `git status` these files should not be listed in the output)

6.  Load `tidyverse`, `ggplot2` and any other packages you find useful (`arrow`, `lubridate`, etc.)

```{r load-data}
# TODO: Load packages and data here
#Example structure (adjust paths/names to match the repo):
library(tidyverse)
library(arrow)
bids <- read_parquet("data/bids_data_vDTR.parquet")
glimpse(bids)
```

------------------------------------------------------------------------

# 1. Initial Orientation (10–15 minutes)

Answer the following in complete sentences. Use code chunks to support your answers, but write the answers in prose.

1.  How many rows and columns are in the dataset?
2.  According to the data dictionary, what does each row represent?
3.  Which variable(s) are the `key(s)` (i.e., the row identifiers)
3.  Which variables appear:
    -   numerical?
    -   categorical?
    -   suspicious or inconsistent with the dictionary?
4.  Name **two variables** you expect to matter most to advertisers and explain why.

```{r setup, message=FALSE}
library(tidyverse)
library(arrow)

bids <- read_parquet("data/bids_data_vDTR.parquet")
```
```{r q1}
dim(bids)
```
#As shown above, there are 15 cols and 443969 rows

#Q2

According to the data dictionary, each row represents one bid line within an auction.

#Q3
The primary keys are AUCTION_ID, PUBLISHER_ID, and DATE_UTC

#Q4
Numerical Variables: PRICE, RESPONSE_TIME, DEVICE_GEO_LAT, DEVICE_GEO_LONG
Categorical Variables: AUCTION_ID, PUBLISHER_ID, DEVICE_TYPE
Suspicious Variables: PRICE (stored as char) and DEVICE_GEO_REGION (invalid state codes like "oregon) 

#Q5 
The first variable we expect to matter most to advertisers is price, or the cost advertisers are willing to pay to show their ad. This is an obvious choice for a relevant variable as it ultimately determines who wins a bid. In other words, price is a strong predictor of win probability. Secondly, we imagine that the ad slot size variable will be relevant to advertisers. This variable should be important because advertisers will adjust their bid strategy to specific ad formats.
------------------------------------------------------------------------

# 2. Data Exploration Using `dplyr` (30–40 minutes)

Use functions you are comfortable with from `dplyr` and `tidyr`.
Tables and summaries should be created in code chunks; explanations should be written as text.

## 2.1 Geographic Exploration

Explore the geographical fields (such as `DEVICE_GEO_COUNTRY`, `DEVICE_GEO_REGION`, `DEVICE_GEO_CITY`, `DEVICE_GEO_ZIP`).

Tasks:

1.  Create tables with the **top 3 regions** and the **top 10 cities** by count of rows.
2.  Compare the region codes to what the data dictionary says they should look like.
3.  Identify **at least one** region code that is clearly suspicious, and explain why.

#Q1
```{r geo-explore}
library(tidyverse)

## Top regions
bids %>% count(DEVICE_GEO_REGION, sort = TRUE) %>% slice_head(n = 3)

```
```{r geo-explore}
library(tidyverse)

## Top cities
bids %>% count(DEVICE_GEO_CITY, sort = TRUE) %>% slice_head(n = 10)

```

#Q2
The region codes should all be explicitly written as "OR", however there are many region codes with an incorrect format. 

#Q3
```{r geo-explore}
library(tidyverse)

## Suspicious region code
bids %>% filter(is.na(DEVICE_GEO_REGION) | DEVICE_GEO_REGION %in% c("", "oregon")) %>% count(DEVICE_GEO_REGION)

```
#Q3 Interpretation:
The region code in question that is clearly suspicious is the region code "oregon." The data dictionary specifies that region codes must be written as a standard USPS abbreviation. Therefore, if we are concerned with Oregon as a region, the code should be given as "OR" instead of "oregon." This clearly presents an issue, and thus is suspicious.

------------------------------------------------------------------------

## 2.2 Price Behavior

Study the `PRICE` variable.

Tasks:

1.  Produce numerical summaries of `PRICE` (e.g., min, max, median, selected quantiles).
2.  Identify implausible price ranges or values and explain why they are implausible.
3.  Investigate whether suspicious prices seem to cluster by **one** of the following:
    -   publisher,
    -   region, **or**
    -   ZIP code.

Choose only one dimension and describe what you find.

#Q1
```{r price-explore}
## Price is incorrectly being stored as char, so must convert to numerical.
bids <- bids %>% mutate(PRICE = as.numeric(PRICE))
summary(bids$PRICE)
quantile(bids$PRICE, probs = c(0, 0.01, 0.05, 0.5, 0.95, 0.99, 1), na.rm = TRUE)
```
#Q2
```{r price-explore}
## Price is incorrectly being stored as char, so must convert to numerical.
bids %>% filter(PRICE <= 0 | PRICE > quantile(bids$PRICE, 0.99, na.rm = TRUE)) %>% count()
```
Above you see that there are 4552 price values that are lower than zero, or greater than the 99% quantile.
#Q3
```{r price-explore}
## Suspicious prices by PUBLISER_ID
bids %>% mutate(suspicious = PRICE <= 0 | PRICE > quantile(bids$PRICE, 0.99, na.rm = TRUE)) %>% group_by(PUBLISHER_ID, suspicious) %>% summarise(count = n(), .groups = "drop") %>% arrange(desc(count))
## Suspicious prices by Region
bids %>% mutate(suspicious = PRICE <= 0 | PRICE > quantile(bids$PRICE, 0.99, na.rm = TRUE)) %>% group_by(DEVICE_GEO_REGION, suspicious) %>% summarise(count = n(), .groups = "drop") %>% arrange(desc(count))
## Suspicious prices by ZIP
bids %>% mutate(suspicious = PRICE <= 0 | PRICE > quantile(bids$PRICE, 0.99, na.rm = TRUE)) %>% group_by(DEVICE_GEO_ZIP, suspicious) %>% summarise(count = n(), .groups = "drop") %>% arrange(desc(count))
```
#Q3 Interpretation:
When looking at data grouped by region, we find that suspicious prices do seem to cluster by region. We generally see that regions containing suspicious region codes show more pricing anomalies than other regions. This suggests that frequency of suspicious pricing issues is positively correlated with quality issues in geographic data.
------------------------------------------------------------------------

## 2.3 Response Time Behavior

Investigate the `RESPONSE_TIME` variable.

Tasks:

1.  Examine its data type and typical values.
2.  Look for common patterns or prefixes/suffixes in the values.
3.  Identify an issue that would prevent straightforward numerical analysis.
#Q1
```{r rt-explore}
library(tidyverse)
summary(bids$RESPONSE_TIME)
head(bids$RESPONSE_TIME, 20)
```
#Q2
```{r rt-explore}
# Show examples of problematic values
bids %>% count(RESPONSE_TIME) %>% arrange(desc(n)) %>% head(10)
```
#Q3
The clear issue we see with the RESPONSE_TIME variable is that it is stored as a character variable instead of a numeric variable, which makes direct statistical computations impossible. We can easily see that some values contain non-numeric symbols or shaky formatting. This suggests that the data must be cleaned, and RESPONSE_TIME should be converted into a numeric variable before straightforward numerical analysis can be conducted.

------------------------------------------------------------------------

# 3. Visualization Challenges (45–60 minutes)

Create **three** high-quality visualizations using `ggplot2`.

Each figure must include:

-   A clear and professional title
-   Labeled axes
-   A readable theme (e.g., `theme_bw()`, `theme_minimal()`)
-   Thoughtful design choices (color, faceting, ordering, etc.)
-   A **3–5 sentence interpretation**

## 3.1 Plot 1 — Distribution of Bid Prices

Create a visualization that reveals:

-   The overall shape of the price distribution
-   Outliers or impossible values
-   Any issues you suspect based on the data dictionary

```{r plot-price}
# Convert price to numerical, create histogram between 0 and 99th percentile of PRICE.
bids <- bids %>% mutate(PRICE = as.numeric(PRICE))

ggplot(bids, aes(x = PRICE)) +
  geom_histogram(binwidth = 0.01, boundary = 0) +
  coord_cartesian(xlim = c(0, quantile(bids$PRICE, 0.99, na.rm = TRUE))) +
  labs(
    title = "Distribution of Bid Prices",
    x = "Bid Price",
    y = "Number of Auctions"
  ) +
  theme_minimal()

# Histogram that includes that massive amount of outliers.
ggplot(bids, aes(x = PRICE)) +
  geom_histogram(binwidth = 0.01) +
  labs(
    title = "Distribution of Bid Prices",
    x = "Bid Price",
    y = "Number of Auctions"
  ) +
  theme_minimal()

```
There are many entries of PRICE data that are invalid according to the data dictionary, these must be removed to get a useful graph. 

#Interpretation:
Since the first histogram is cut off at the 99th percentile, it suggests that we may have right-skewness in the data. In the second histogram, we see that we do in fact have a strongly right-skewed distribution. In this second histogram, we do not stop the distribution at the 99th percentile, and thus we see a large tail of outliers. The data dictionary dictates that we should remove many of these outliers, as these are "invalid." Therefore, to obtain a more accurate view of typical bidding behavior, these extreme outliers should be removed.

------------------------------------------------------------------------

## 3.2 Plot 2 — Price by Zip City

Compare a central price measure (mean or median) across cities

Guidance:

-   Be explicit about whether you use mean or median.
-   Consider sorting cities by the measure you plot.
-   Highlight any cities whose price behavior appears inconsistent or suspicious.

```{r plot-price-region}
library(tidyverse)

# Convert price to numerical
bids <- bids %>%
  mutate(PRICE = as.numeric(PRICE))

# median price by city and find suspicious cities
city_price <- bids %>% group_by(DEVICE_GEO_CITY) %>% summarise(median_price = median(PRICE, na.rm = TRUE), n = n(), .groups = "drop") %>% arrange(desc(n)) %>% slice_head(n = 20) %>% mutate( suspicious = median_price < 0 | median_price > 1 | DEVICE_GEO_CITY == "NA" | is.na(DEVICE_GEO_CITY))

# Plot median price by city, suspicious cities red, normal cities blue
ggplot(city_price, aes(
  x = reorder(DEVICE_GEO_CITY, median_price),
  y = median_price,
  fill = suspicious
)) +
  geom_col() +
  scale_fill_manual(
    values = c("FALSE" = "steelblue", "TRUE" = "red"),
    labels = c("Normal", "Suspicious")
  ) +
  coord_flip() +
  labs(
    title = "Median Bid Price Across Top 20 Cities",
    x = "City",
    y = "Median Bid Price",
    fill = "City Status"
  ) +
  theme_minimal()
```
#Interpretation:
The plot shows the median bid prices across the top twenty cities. We chose the median instead of the mean as our desired statistic because we saw in 3.1 that the price distribution is highly right-skewed, and thus the mean would be distorted by the tail of extreme outliers. Cities that "stand out" with either very low or very high median values are highlighted red and labeled as suspicious. These suspicious cities indicate that further cleaning or manipulation of the data may be required.

------------------------------------------------------------------------

## 3.3 Plot 3 — Analyst’s Choice

Choose a visualization that you believe would be useful to a data science team at an advertising company.

Possible ideas:

-   Auction volume by hour of day
-   Differences between winning and losing bids
-   ZIP code irregularities
-   Response time patterns
-   Publisher-level differences

Your plot should answer a clear question, and your interpretation should explain what you learned.

```{r plot-analyst-choice}
# Clean response time into a numeric
bids <- bids %>% mutate( RESPONSE_TIME_NUM = as.numeric(str_remove(RESPONSE_TIME, "RESPONSE_TIME:\\s*")), PUBLISHER_ID = as.factor(PUBLISHER_ID), BID_WON = as.factor(BID_WON))

# Compute median response time by publisher
publisher_rt <- bids %>% group_by(PUBLISHER_ID) %>% summarise(median_rt = median(RESPONSE_TIME_NUM, na.rm = TRUE), n = n(), .groups = "drop") %>%  arrange(desc(n)) %>% slice_head(n = 15)

# Plot median response time for publishers
ggplot(publisher_rt, aes(
  x = reorder(PUBLISHER_ID, median_rt),
  y = median_rt
)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Median Response Time by Top 15 Publishers",
    x = "Publisher ID",
    y = "Median Response Time (ms)"
  ) +
  theme_minimal()
```
#Interpretation:
This plot shows the differences in median response time across the top 15 publishers by bid volume. Certain publishers have significantly lower median response times, indicating more efficient turnaround. In contrast, several publishers have much higher median response times, suggesting the presence of inefficiencies. This plot highlights to us which publishers might benefit from improvements in infrastructure or other processes to speed up response time.

------------------------------------------------------------------------

# 4. Synthesis & Reporting (20–25 minutes)

## 4.1 Data Quality Issues

Based on your work above, list **3–4** data quality issues you discovered.
For each issue:

-   Name the affected variable(s).
-   Describe what the issue is.
-   Provide evidence (e.g., from a summary, table, or plot).
-   Suggest one way you would address it in a later **data cleaning** lab.
*(Atefeh Answer here)*
*(Write your answer here in paragraphs or bullet points.)*

------------------------------------------------------------------------

## 4.2 Implications for Analytics

In 1–2 paragraphs, discuss how the issues you identified could affect:

-   Business decisions,
-   Reporting to advertisers, and/or
-   Predictive modeling.

Which issues are most critical to fix before building models, and why?
*(Atefeh Answer here)*
*(Write your answer here.)*

------------------------------------------------------------------------

## 4.3 Reflection: Tools, Workflow, AI Use

Write 5–8 sentences reflecting on:

-   Which R tools or approaches were most useful in this lab.
-   What worked well in your Git/gitHub workflow and team collaboration.
-   One thing you would change next time to improve your process.
-   Whether and how you used generative AI (if at all), and how it affected your understanding.
*(Atefeh Answer here)*
*(Write your reflection here.)*

